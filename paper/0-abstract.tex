\begin{abstract}
{Practitioners in medicine, business, political science, and other fields are increasingly aware that decisions should be personalized to each patient, customer, or voter. A given treatment (e.g. a drug or advertisement) should be administered only to those who will respond most positively, and certainly not to those who will be harmed by it. Individual-level treatment effects can be estimated with tools adapted from machine learning, but different models can yield contradictory estimates. Unlike risk prediction models, however, treatment effect models cannot be easily evaluated against each other using a held-out test set because the true treatment effect itself is never directly observed. Besides outcome prediction accuracy, several approaches that use held-out data to evaluate treatment effects models have been proposed, but they are largely underutilized. We develop a framework that classifies these approaches into what we call $\mu$-error, $\tau$-error, and decision value estimators. We discover a relationship between decision value and $\tau$-error and show that model selection on the basis of certain $\tau$-errors is valid. We compare these approaches using simulations of both randomized and observational data. Based on our empirical and theoretical results, we advocate for the standardized use of estimated decision value or transformed-outcome $\tau$-MSE for individual treatment effect model selection and validation. Model selection on the basis of $\mu$-error is also empirically justified and may be appropriate in many cases.}{Individual treatment effects; heterogenous treatment effects; model selection; model validation; causal inference.}
\end{abstract} 