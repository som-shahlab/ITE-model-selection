\section{Introduction}

For a particular individual $i$ characterized by a vector of covariates $x_i$, a decision maker must chose between prescribing an intervention $w_i=1$ or no intervention $w_i=0$. The intervention (treatment) may be a drug, an advertisement, a campaign email etc. The decision-maker's goal is to maximize some outcome $y_i$ for that patient or customer, which may be their lifespan, their net purchases, their political engagement etc. Inferring the effects of the treatment on the outcome is a causal inference problem. Using the potential outcomes framework (\citealp{Rubin2005}), we write the conditional means of the potential outcomes as $\mu_0(x) = E[Y|W=0,X=x]$ and $\mu_1(x) = E[Y|W=1,X=x]$. The estimand in question is the conditional average treatment effect $\tau(x_i) = \mu_1(x_i) - \mu_0(x_i)$, which is the expected difference in potential outcomes under the alternative interventions for the individual in question. In different fields this quantity is alternatively called the individual treatment effect, individual causal effect, individual benefit, or individual lift. If the true conditional mean functions $\mu_w(x)$ are known, the rule (policy) that assigns each individual $x_i$ their optimal treatment is $d(x) = \underset{w \in \{0,1\}}{\text{argmax}} \ \ \mu_w(x)$, or, alternatively, $d(x) = I(\tau(x) > 0)$ where $I$ is the indicator function. Generally, the conditional mean functions $\mu_w$ are unknown, meaning that there is uncertainty about the optimal treatment policy $d(x)$.

Prior to the development of modern statistical methods, policies were generally one-size-fits-all prescriptions based on estimates of the average treatment effect $\bar\tau = E[\tau(X)]$ (\citealp{Segal:ub}). These experiments limit individual heterogeneity by imposing strict criteria on the population under study (\citealp{Stuart:2014id}). Recently, however, researchers in multiple domains have attempted to leverage modern statistical technology and real-world data to tailor decisions to individuals; this phenomena is exemplified by the rise of personalized medicine (\citealp{Ferreira:2017fv}) and targeted advertisement (\citealp{Ascarza:2018ie, Matz:2017ix}). Decision-makers recognize that treating to the average, while expedient, does not result in the best outcome for all individuals (\citealp{Kravitz:2004fa,Segal:ub}). 

Note that estimating individual treatment effects is not the same as estimating personalized risks or prognoses with prediction models (e.g. for a heart attack, customer churn, or non-voting). Prediction models only predict what would happen to the individual given standard practice, not the difference of what would happen if a treatment were or were not given. As such, prediction models by themselves are often of little practical utility unless the effects of available treatments are known and relatively constant. If that is not the case, targeting high-risk individuals is not an optimal strategy: there may be high-risk individuals who do not respond or respond negatively to the treatment, and low-risk individuals who would respond very positively (\citealp{Ascarza:2018ie}).

There are currently a number of methods to estimate individual treatment effects from randomized data. The process of estimating these effects is alternatively referred to as heterogenous effect modeling, uplift modeling, or individual treatment effect modeling. These approaches can also be used for observational data if certain assumptions are met or if combined with propensity score or matching techniques.

A manual subgroup analysis is the traditional approach to heterogenous treatment effect estimation. A subgroup analysis partitions the population of individuals into manually-specified subgroups and typically estimates an average treatment effect in each subgroup using traditional methods (i.e. linear or logistic regression) (\citealp{Gail:1985ft}). This approach requires a high degree of domain knowledge is prone to multiple-hypothesis testing problems if subgroups are not pre-specified. 

An alternative is to use any supervised learning method (e.g. LASSO, random forest, neural network) to fit functions $\hat\mu_0$ and $\hat\mu_1$ that estimate the conditional means $\mu_0$ and $\mu_1$ of the potential outcomes. These estimates are then used to estimate the treatment effect $\hat\tau(x) = \hat\mu_1(x) - \hat\mu_0(x)$ (\citealp{Gutierrez:2016tq, Austin:2012cy, Snowdn:2011ef}). This can be done by regressing the observed outcomes on the covariates in the untreated group to get $\hat\mu_0$ and regressing the observed outcomes on the covariates in the treated group to get $\hat\mu_1$. \citet{Kunzel:2017vg} call this approach T-learning (T for ``two models''). Similarly, it is possible to fit a single model $\hat\mu(x,w)$ and estimate the treatment effect in the same way as above by letting $\hat\mu_w(x) = \hat\mu(x,w)$ (S-learning, for single-model) \citealp{Kunzel:2017vg}. T-learning and S-learning together have been referred to as simulated twins, g-computation, counterfactual regression, or conditional mean regression. 

Modeling the conditional means is a valid approach, but many have noted that since the object of interest is the treatment effect we may be better off modeling it directly without appeal to the correctness of $\hat\mu_0$ and $\hat\mu_1$. Approaches in this vein include \citet{Zhao:2017vi}, \citet{Athey:2016wm}, \citet{Powers:2017wd}, and \citet{Nie:2017vi}. 

Among the variety of approaches and the number of hyper-parameter settings within each approach, which is best? As is the case with all statistical learning problems, there is no free lunch (\citealp{Wolpert:1996fp}): different methods will give better or worse estimates depending on the application. Indeed, using a large set of diverse simulations, \citet{Dorie:2017uo} find that the only somewhat consistent predictor of the success of a causal inference method is its ability to ``flexibly'' model the conditional means or treatment effect. Although that result surely depends upon the particulars of their simulations, it parallels the common knowledge in the machine learning literature that deep nets and additive regression trees often outperform linear models for real-world applications. However, even limiting ourselves to flexible treatment effect modeling methods, we are left with a panoply of approaches and hyper-parameter settings to chose from. 

We digress briefly to discuss the standard supervised learning setting where the task is to estimate $y$ given $x$ by building an estimator $\hat{\mu}(x)$. There we can use the diversity of machine learning approaches to our advantage by performing model selection. Given $M$ modeling approaches and/or hyper-parameter settings, we build $M$ estimators $\{\hat \mu_1, \hat \mu_2 \dots \hat \mu_m \dots \hat \mu_M\}$. The quantity of interest in this case is the expected prediction risk of the model when it is applied to new data, according to some loss $l$. We express that as $E[l(\hat \mu_m(X), Y)]$. The idea of model selection is to estimate this expected risk for each of our models and find the model that minimizes it. There are several ways to estimate this risk, including information criteria, but data-splitting is the easiest and most widely applicable (\citealp{esl:2009wc, Arlot:2010fl, Dudoit:2005jw}). Before fitting the models, the observations are randomly split into training and validation samples. The models are fit on the training sample $\mathcal{T}$ and evaluated on the validation sample $\mathcal{V}$. The risk of each model is estimated with $\frac{1}{|\mathcal{V}|}\sum_{i \in \mathcal{V}}^{|\mathcal{V}|} l(\hat \mu_m (x_i), y_i)$. In cross-validation, this process is repeated round-robin across different random splits of the data and the estimated risks are averaged per model.

This approach breaks down for treatment effect estimation because the true treatment effect is never observed in any sample. In this case, the quantity of interest is the $\tau$-risk: $E[l(\hat\tau, \tau)]$. We would like to evaluate models $\{\hat\tau_1, \hat\tau_2 \dots \hat \tau_m \dots \hat \tau_M\}$ by estimating their $\tau$-risk on a validation set via $\frac{1}{|\mathcal{V}|}\sum_{i \in \mathcal{V}}^{|\mathcal{V}|}  l(\hat \tau_m (x_i), \tau(x_i))$ (this quantity has been called the precision in estimating heterogenous effects or PEHE by \citet{Hill2011}). The problem is that we never observe $\tau(x_i)$ directly (we only see one of the two potential outcomes) and thus have nothing to compare $\hat\tau(x_i)$ to. This estimator of $\tau$-risk is thus infeasible.

Several treatment effect model selection approaches have been suggested in the literature, but none of them enjoys the wide use and dominance that prediction error cross-validation has in the supervised learning setting. Most approaches are not general-purpose in that they require that the set of estimators $\{\hat\tau_1, \hat\tau_2 \dots \hat \tau_m \dots \hat \tau_M\}$ come from a specific class of models. For example, \citet{Powers:2017wd} and \citet{Athey2015} both use selection methods that are specific to the models they propose. The Focused Information Criterion (FIC) (\citealp{Claeskens:2003ck}) is a promising approach, but as of yet cannot be used to select between most machine learning estimators (\citealp{Jullum:2012uo}). \citet{Alaa:tj} propose an empirical Bayes approach for optimal prior selection. \citet{Nie:2017vi} circumvent the problem with a different method of treatment effect estimation which precludes comparison to standard approaches, but allows for internal model selection using prediction error. 

It is clear that we lack a go-to general-purpose approach for applied researchers to select among treatment effect models. The absence of a standard leaves the door open for poor practice, which we hope to combat by presenting our findings here. Using valid model selection will ensure that better models result from primary research, making it more certain, for instance, that a patient will benefit from their treatment or that an advertisement will reach interested parties. 

In section \ref{approaches}, we describe several general-purpose approaches for treatment effect model selection and introduce a didactic framework to relate them to each other. Section \ref{simulations} describes our experiments and results. We conclude in section \ref{conclusion} with a summary of our contributions and recommendations for researchers interested in estimating individual treatment effects.
