\section{Conclusion}
\label{conclusion}

Although prediction error cross-validation is widely used to select between predictive models, there is no consensus on how to perform model selection for individual treatment effects models. Several general-purpose approaches have been proposed. We describe each of these approaches and demonstrate that many of them work by minimizing a loss between the treatment effect function estimated from the training set (then applied to the validation set) and a treatment effect directly estimated from the validation set. The validation set estimate serves as a plug-in for the true individual treatment effect of each individual in the validation set. We establish some conditions on the validation set estimator that ensure statistically sound model selection. We also explore methods that are based on optimizing decision value and demonstrate a connection between them and the treatment effect loss-based methods. 

Somewhat surprisingly, minimizing the prediction MSE (section \ref{sec:pred-error}) of the potential outcomes models is the best performing model selection approach according to our simulations. Our work does not establish why that is the case, but we speculate that this minimizing prediction MSE may trade lower variance for slightly increased bias relative to the other approaches considered. It should be noted that model selection based on prediction MSE fared poorly in preliminary experiments where the potential outcomes were fit as a single model $\hat\mu(x,w)$. This is likely because the single-model approach effectively regularizes the treatment effect estimate. We do not include those results here because the single-model approach has been found to be theoretically deficient for that same reason \cite{Alaa:tj}, but we suggest using an metric other than prediction MSE if a one-model approach is required. 

Despite its good performance, prediction MSE is not a general-purpose method for treatment effect model selection because it requires that the user have access to the potential outcomes models $\hat\mu_w$. If only the estimated treatment effects are available, our results suggest that estimates of decision value (section \ref{sec:value}) should be used to select among treatment effect models. Although other methods perform almost as well in our simulations, estimated decision value has several other advantages. Estimated decision value is a direct estimate of the quantity that is of ultimate interest to decision-makers and it is the only metric that naturally extends to studies with more than two treatment regimens without requiring predictive models for each potential outcome \cite{Zhao:2017vi}. 

It is interesting that the three AUC-style selection approaches perform variably. Further investigation of the theoretical properties of these approaches is warranted.

In conclusion, we recommend that researchers use either outcome prediction MSE (when possible) or estimated decision value (more generally) to select between treatment effect models. 

% optimizing mse works because 0 mse -> optimal value, even though you can get better value with higher mse in general


