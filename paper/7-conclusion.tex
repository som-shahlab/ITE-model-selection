\section{Conclusion}
\label{conclusion}

Although prediction error cross-validation is widely used to select between predictive models, there is no consensus on how to perform model selection for individual treatment effects models. Several general-purpose approaches have been proposed. We describe each of these approaches and demonstrate that many of them work by minimizing a loss between the treatment effect function estimated from the training set (then applied to the validation set) and a treatment effect directly estimated from the validation set ($\tau$-error). The validation set estimate serves as a plug-in for the true individual treatment effect of each individual in the validation set. We establish some conditions on the validation set estimator that ensure statistically sound model selection. We also explore methods that are based on optimizing decision value and demonstrate a connection between them and the treatment effect loss-based methods. 

Somewhat surprisingly, minimizing the prediction MSE ($\mu$-error: section \ref{sec:pred-error}) of the potential outcomes models is the best performing model selection approach according to our simulations. It should be noted that model selection based on prediction MSE fared poorly in our preliminary simulation experiments when the potential outcomes were fit as a single model $\hat\mu(x,w)$. This is likely because the single-model approach effectively regularizes the treatment effect estimate. We do not include those results here because the single-model approach has been found to be theoretically deficient for that same reason \cite{Alaa:tj}, but we suggest using a metric other than prediction MSE if a one-model approach is required. 

Estimated decision value suffers from higher variance than estimated $\mu$-error. Only the weighted outcomes from the ``lucky'' individuals are used when estimating value, meaning there is higher variance in the computed mean. In contrast, $\mu$-error makes use of all of the observed outcomes in the validation set. It may be possible to reduce the variance of the value estimator with a doubly-robust approach in the style of \citet{Zhang:2012em}. It may also be possible to select models based on a heuristic combination of value and $\mu$-error.

Despite its good performance in our simulations, $\mu$-error is not a general-purpose method for treatment effect model selection because it requires that the user have access to the potential outcomes models $\hat\mu_w$. If only the estimated treatment effects are available, our results suggest that estimates of decision value (section \ref{sec:value}) should be used to select among treatment effect models. Although other methods perform almost as well in our simulations, estimated decision value has several advantages. For one, it is a direct estimate of the quantity that is of ultimate interest to many decision-makers. It is also is the only available metric besides $\mu$-error that is usable in studies with more than two treatment regimens \cite{Zhao:2017vi}. 

Based on our empirical and theoretical results, we advocate for the standardized use of estimated decision value for individual treatment effect model selection and validation. Model selection on the basis of $\mu$-error is also empirically justified and may be appropriate in some cases.


