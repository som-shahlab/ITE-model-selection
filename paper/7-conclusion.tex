\section{Conclusion}
\label{conclusion}

Although prediction error cross-validation is widely used to select between predictive models, there is no consensus on how to perform model selection for individual treatment effects models. Several general-purpose approaches have been proposed. We describe each of these approaches and demonstrate that many of them work by minimizing a loss between the treatment effect function estimated from the training set (then applied to the validation set) and a treatment effect directly estimated from the validation set ($\tau$-error). The validation set estimate serves as a plug-in for the true individual treatment effect of each individual in the validation set. We establish some conditions on the validation set estimator that ensure statistically sound model selection. We also explore methods that are based on optimizing decision value and demonstrate a connection between them and the treatment effect loss-based methods. 

Somewhat surprisingly, minimizing the prediction MSE ($\mu$-error: section \ref{sec:pred-error}) of the potential outcomes models is the best performing model selection approach according to our simulations. It should be noted that model selection based on prediction MSE fared poorly in other simulation experiments when the potential outcomes were fit as a single model $\hat\mu(x,w)$. This is likely because the single-model approach effectively regularizes the treatment effect estimate. We do not include those results here because the single-model approach has been found to be theoretically deficient for that same reason \cite{Alaa:tj}, but we suggest using a metric other than prediction MSE if a one-model approach is required (e.g. when semi-parametrically estimating a proportional hazards model in a survival setting).

Estimated decision value suffers from higher variance than estimated $\mu$-error. Only the weighted outcomes from the ``lucky'' individuals are used when estimating value, meaning there is higher variance in the computed mean. In contrast, $\mu$-error makes use of all of the observed outcomes in the validation set. It may be possible to reduce the variance of the value estimator with a doubly-robust approach in the style of \citet{Zhang:2012em}. It may also be possible to select models based on a heuristic combination of value and $\mu$-error.

If estimated potential outcomes are not available, our results suggest that estimates of decision value (section \ref{sec:value}) or transformed-outcome $\tau$-MSE (section \ref{trans-mse}) should be used to select among treatment effect models. If the modeled outcome is the only quantity of interest in determining the treatment, we recommend using value for model selection. If other relevant outcomes (e.g. adverse effects) might affect the choice of treatment, a good estimate of the effect of the treatment on each outcome is necessary. Selection with decision value does not optimize for the precise value of the estimated treatment effect, so in these cases we recommend using transformed-outcome $\tau$-MSE to select between models for each outcome. Alternatively, the analyst could combine the different outcomes into a single number representing total utility and then select via decision value.

Based on our empirical and theoretical results, we advocate for the standardized use of estimated decision value or transformed-outcome $\tau$-MSE for individual treatment effect model selection and validation. Model selection on the basis of $\mu$-error is also empirically justified and may be appropriate in some cases.